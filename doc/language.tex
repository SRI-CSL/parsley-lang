\documentclass[letterpaper]{article}

\usepackage{cite}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{amsmath,amsthm,amssymb,mathtools}
\usepackage{prftree}

\usepackage{tikz}
\usetikzlibrary{calc,positioning,fit,shapes}

\newcommand{\todo}[1]{{\color{red}[TODO: #1]}}

\title{The Parsley Data Definition Language}
\author{The Parsley Team}

\begin{document}
\maketitle

\begin{abstract}
  Any program that reads formatted input relies on parsing software to
  check the input for validity and transform it into a representation
  suitable for further processing.  Many security vulnerabilities can
  be attributed to poorly defined grammars, incorrect parsing, and
  sloppy input validation.  In contrast to the syntax for programming
  languages, grammars for even common data formats such as DNS and PDF
  are typically context-sensitive and heterogenous.  However, as in
  programming languages, a standard notation or {\em language} to
  express these data format grammars can address poor or ambiguous
  definitions, and the automated generation of correct-by-construction
  parsers from such grammar specifications can yield correct and type-
  and memory-safe data parsing routines.

  This document describes the design of Parsley, a declarative data
  format definition language that combines grammars and constraints in
  a modular way.  It describes the syntax, type system and semantics
  of the language.  It will eventually describe its compiler, which
  will generate an executable parsing library from a Parsley
  specification, and other outputs to enable the verification of the
  correctness of generated parser.
\end{abstract}

\section{Language Design}
\label{s:design}

The language has the following design goals:

\begin{itemize}
\item A useful foundational set of parser primitives and combinators,
\item A capacity to capture context-sensitivity and data-dependency
  via a constraint system, and
\item  A module system that enables nested grammars and composes with
  the constraint system.
\end{itemize}

We employ the following techniques to achieve these goals:

\begin{itemize}
\item The core structure of a Parsley specification is provided by a
  {\em parsing expression grammar (PEG)} \cite{ford2004popl},
  specified in notation similar to {\em extended BNF (EBNF)} for
  grammar productions.  Although {\em context-free grammars (CFGs)}
  use the EBNF notation, there are critical differences in the PEG
  notation: (a) the choice combinator in PEGs is ordered, as opposed
  to non-deterministic in CFGs, and (b) the PEG notation includes
  syntactic predicates that do not occur in CFGs.  The choice of a PEG
  core provides us a core set of primitives and combinators we can
  build on.

\item Context management is provided by a fairly traditional
  attribute-grammar system, where the expression language for
  attribute computations is purely functional and strongly-typed.  In
  Parsley, non-terminals have user-defined attributes, while terminals
  have a default attribute value of type byte or byte-string.  This
  provides us with the tools needed to capture context-sensitivity.

\item Additional context-sensitivity is provided by a constraint
  system that guards further processing within a non-terminal
  production.  The constraint language uses the attribute system to
  perform context-sensitive checks, and cleanly enables data-dependent
  parsing.

\item A module system allows the composition of independent grammars.
\end{itemize}

The expression sublanguage used in attribute updates and constraints
is a strongly typed polymorphic functional language supporting
user-defined types and functions.  It includes a standard library of
common types and utility functions.  The expression and data type
sublanguage is designed to ensure that recursive and iterative
computations always terminate.

\section{Language Use}
\label{s:use}

\begin{figure*}[!ht]
  \centering
  \resizebox{10cm}{!}{\input{figs/parsley-pipeline-tikz}}
  \caption{Parsley in context.}
  \label{f:pipeline}
\end{figure*}

The typical use of a Parsley specification is via the workflow
illustrated in Figure~\ref{f:pipeline}.

The Parsley compiler performs type and semantic checks on a given
Parsley specification.  The type checks correspond to standard
polymorphic type checking~\cite{Dunfield13:bidir}\cite{zhao19:bidir},
with rules to handle grammar productions.  In addition, attribute
usage checks are performed, such as for $L$-attributedness (see
below).

The compiler generates prover definitions that are used to perform
safety checks: for example, a check to ensure that data-dependent
constructs do not use a data value as an array index without an
appropriate constraint check.  We are developing the safety properties
that can be used by the PVS theorem prover to verify that the Parsley
specification is a `safe' grammar.

We are also defining the parsing automaton that will be generated by
the compiler.  This automaton needs to interleave constraint and
attribute computation with parsing actions that construct the internal
data representation and manipulate the parsing buffer.  When used for
efficiently parsing data, especially network protocols, attribute
computations have to be done on partially constructed parse trees
(unlike the typical use of attribute grammars in programming
languages, where the entire parse tree of a program can be available
before processing).  In our experience of using Parsley to define data
formats, the computations in constraints and attribute updates require
access to a parsing context (via inherited attributes) that is best
handled by $L$-attributed grammars, which are compatible with the
top-down processing of the ``core'' PEG specification.  $L$-attributed
grammars are attribute grammars where attributes in the nodes in the
parse tree to the left of the current node have been assigned their
final values.  This eases the implementation of PEG backtracking, as
assigned attribute values do not need to be unwound.  The generated
automaton is compiled into a library that can be linked into
application code.  We plan to use a Rust code generator to ensure that
the library is type and memory safe, can be linked into C
applications, and is compatible with other languages using the
appropriate wrappers.

The data representation constructed by the automaton contains a {\em
  proof of parse}.  We are building on the approach used in
~\cite{Blaudeau_2020}, which formalized PEG parsing and the generation
of verifiable PEG parsers.  These parsers annotate the constructed
data representation with grammar metadata that can be used to verify
that the representation is a valid parse of the given input data for
the given Parsley specification.  This verification is done in an
independent verifier, which is simple enough to include in the
application itself.

\subsection*{Unresolved issues}

The API between the application and the parsing library will dictate
crucial implementation choices, and hence impact the code generation
pipeline.  This API might differ across applications parsing the same
format, and these types of API often differ across different types of
formats (e.g. streaming network formats versus document formats).

A crucial requirement is to ensure that the parsing automaton is not
Turing-complete; i.e. arbitrary input data cannot cause
Turing-complete computation within the parsing library.  We are
attempting to provide formal guarantees that this will be the case.

\section{Abstract syntax}
\label{s:syntax}

The abstract syntax of Parsley is shown in
Figure~\ref{f:parsley-syntax}, and has two layers: the expression
sublanguage is shown first, followed by the grammar sublanguage.

\begin{figure}
  \begin{tabular}{l c l l}
    Paths        & $p$      & ::= & $ x\ |\ p.x $ \\
    Constants    & c        & ::= & 0,1,\ldots\ $|$\ `A', `B', \ldots\ $|$\ \ldots \\
    Attributes   & $l$      & ::= & $ l^i\ |\ l^s $ \\
    Base types   & $\nu$    & ::= & $ \texttt{unit}\ |\ \texttt{uint8}\ |\ \texttt{int32}\ |\ \ldots $ \\
    Monotypes    & $\tau$   & ::= & $ \alpha\ |\ \nu\ |\ (\tau_i)\ |\ \tau\rightarrow\tau\ |\ \sum_i C_i\tau_i\ |\ \{l_i:\tau_i\}\ |\ \texttt{typeof}(N) $ \\
    Types        & $\sigma$ & ::= & $ \tau\ |\ \forall\alpha.\sigma\ |\ \sigma\rightarrow\sigma $ \\
    Expressions  & $e$      & ::= & $ p\ |\ \textrm{c}\ |\ C_i\ e\ |\ (e_i)\ |\ e\ e\ |\ e\ \texttt{op}\ e\ |\ (e : \tau)\ |\ e.l $ \\
                 &          &     & $|\ \textrm{case}\ e\ \{\rho_i, e_i\}\ |\ \textrm{let}\ \rho=e\ \textrm{in}\ e\ |\ e\ \sim\ C |\ f\ e $ \\
    Patterns     & $\rho$   & ::= & $ x\ |\ (\rho_i)\ |\ C\rho $ \\
    Functions    & $f$      & ::= & $ x := (x_i:\sigma_i)\rightarrow\sigma\ \{e\} $ \\
    Statements   & $s$      & ::= & $ p = e $ \\
                 &          &     & \\
    Constraints  & $\phi$   & ::= & $ e $ \\
    Actions      & $a$      & ::= & $ \{s_i\} $ \\
    Rules        & $r$      & ::= & $ \epsilon\ |\ \textrm{c}\ |\ (x=)^?N\{l_i=e_i\}\ |\ \phi\ r $ \\
                 &          &     & $|\ r\ r\ |\ r\ /\ r\ |\ r^{*e?}\ |\ !r\ |\ !^Rr\ |\ a $ \\
    Productions  & $P$      & ::= & $ N\{l_i:\tau_i\} := r $ \\
    Format       & $F$      & ::= & $ \{ \tau_i, N\{l_i:\tau_i\}, P_i \} $ \\
  \end{tabular}
  \caption{Abstract syntax of the Parsley specification language}
  \label{f:parsley-syntax}
\end{figure}

\subsection*{Expression sublanguage}
\label{ss:lang:expr}

In Figure~\ref{f:parsley-syntax}, $x$ over identifiers, $l$ over
inherited $l^i$ and synthesized $l^s$ attributes, $\alpha$ ranges over
type variables, and $op$ over standard arithmetic and boolean
operators.  Paths $p$ are used to access identifiers across modules.

The type system is a conventional polymorphic type system
with records.  It is equipped with a set of standard base types $\nu$, type
constructors like tuples $(\tau_i)$, functions $\tau\rightarrow\tau$,
sums $\sum_iC_i\tau_i$, records $\{l_i:\tau_i\}$ and
polymorphic type schemes $\forall\alpha.\tau$.  The Parsley library
defines standard data types such as polymorphic lists, sets, and maps.

The expression language is also standard, with tuples $(e_i)$, sums
$C_i e_i$, function application $e\ e$, attribute or record field
selection $e.l$, type constraints $(e:\tau)$, and let bindings and
case expressions that bind patterns within expressions.  The
$e\ \sim\ C$ is a boolean expression that tests if $e$ is a sum with
the $C$ constructor; this is a useful primitive within grammar
constraints.

Parsley supports user-defined higher-ranked polymorphic functions $f$,
where the function arguments have polymorphic types.  The supporting
type system is described in \S\ref{s:typesys}.

Statements are the only imperative constructs, and consist of
assignments to (synthesized) attributes.

\subsection*{Grammar sublanguage}
\label{ss:lang:grammar}

We now come to the grammatical constructions: productions, rules, and
actions.  These are based on parsing expression grammars (PEGs)
\cite{ford2004popl}, but are extended with an attribute system and
constraints to capture context sensitivity.  A grammar production
defines the parsing expression for a non-terminal $N$.  Each $N$ is
typed as a record named $\texttt{typeof}(N)$ with its attributes as
the record fields.  Rules $r$ are elemental parsing expressions and
are combined with parsing combinators.  Actions $a$ are used to update
parsing state during parsing, and consist of a sequence of statements
where synthesized attributes are assigned.  The primitive rules are
$\epsilon$, which successfully matches without consuming any input,
and literals $\textrm{c}$, which match if the input has a $c$ prefix,
upon which that prefix is consumed.  The $N\{l_i=e_i\}$ rule matches
if its production matches an input prefix given its inherited
attributes $l_i$ are initialized as specified with expressions $e_i$
evaluated within the parsing context at that point.  The $x=N$
construct names the matched value (of type $\texttt{typeof}(N)$), and
enables access to the values of its attributes as $x.l$ in expressions
appearing within any subsequent constraints, actions, or attribute
initializations.

These primitive rules can be combined with combinators, as in PEG, but
with some extensions.  $r\ r$ denotes the PEG sequence operator, while
$r\ /\ r$ is the PEG ordered choice.  The $!r$ construct is the
\emph{not} syntactic predicate in PEG.  $r^{*e?}$ denotes the Kleene
star, but with an optional bound $e$ that is context sensitive.  If
the bound is present, it limits the number of times that $r$ is
matched.

A parsing rule $r$ can be guarded with a constraint expression $\phi$,
written as $\phi\ r$: the boolean expression $\phi$ is evaluated
before deciding to proceed parsing with rule $r$.  This is a Parsley
extension of PEG, and could be thought of as a \emph{contextual}
predicate: $\phi$ can check the current parsing state, using the
attribute values of syntactic elements in its context.  If this guard
fails, parsing backtracks to the most recent choice point, and
continues with the next alternative.

Parsley is equipped with a module system that enables splitting a
specification into multiple files, and allows data specifications to
be re-used in different contexts.  Paths support the module system
(not shown) by enabling cross-module use of types and syntax elements.

\subsection*{Extensions under development}

The Parsley language is a work-in-progress, and is being adapted as we
attempt to use it to capture more data formats.  The parsing of a PDF
file involves seeking to the end of the file (or a specific marker)
and searching backwards for a syntactic element.  This motivated the
$!^Rr$ construct, which can be considered as a \emph{reverse-not}
predicate: it checks backwards from the current parsing location
whether the parse buffer matches $r$.

We are also considering extending Parsley with primitives to capture
manipulations of the current parsing offset by actions such as
seeking.  Such offset manipulation could either derive declaratively
from the format specification, or procedurally under the control of
the application driving the parser.  A design challenge is to ensure
both types of manipulations are supported and compose well.  In
addition, this is one of the most security-critical aspects of
parsing: ensuring that offsets derived from untrusted data are used in
valid ways.

\section{Type system}
\label{s:typesys}

The polymorphic type system used in Parsley supports higher-ranked
polymorphism with type-inference, using a bidirectional scheme based
on~\cite{Dunfield13:bidir}.  It requires type annotations for
polymorphic function arguments, and allows only predicative type
inference.  This system relies on a polymorphic subtyping scheme
\cite{odersky96} to guide instantiation of polymorphic quantifiers.
We extend this system to the Parsley grammar language as described
below.

Figure~\ref{f:ctxt} defines a typing context $\Gamma$, and shows the
mutually recursive rules for a well-formed context judgment,
$\vdash\Gamma$, and a well-formed type judgment, $\Gamma\vdash\tau$.
The definition of a well-formed context follows the ordered
algorithmic context model
of~\cite{zhao2018,zhao19:bidir,Dunfield13:bidir}, which provides
convenient scoping of type variables introduced during type-checking.

\begin{figure}
  \begin{tabular}{l c l l l}
    Typing context            & $\Gamma$ & ::= & $ \cdot $                       & empty context \\
                              &          &     & $|\ \Gamma, x: \tau $           & program variable \\
                              &          &     & $|\ \Gamma, N: \{l_i:\tau_i\} $ & non-terminal \\
                              &          &     & $|\ \Gamma, \alpha $            & universal type variable \\
                              &          &     & $|\ \Gamma, \beta  $            & existential type variable\\
  \end{tabular}
  $$ $$
  $$ \boxed{\vdash\Gamma} \qquad \boxed{\Gamma\vdash\tau} $$
  $$ \prftree{\prfassumption{\alpha\notin\Gamma}}
             {\vdash\Gamma, \alpha}\qquad
     \prftree{\prfassumption{\beta\notin\Gamma}}
             {\vdash\Gamma, \beta}\qquad
     \prftree{\prfassumption{x\notin\Gamma}}{\prfassumption{\Gamma\vdash\tau}}
             {\vdash\Gamma, x:\tau}\qquad
     \prftree{\prfassumption{N\notin\Gamma}}{\prfassumption{\Gamma\vdash\{l_i:\tau_i\}}}
             {\vdash\Gamma, N:\{l_i:\tau_i\}} $$
  $$ \prfaxiom{\Gamma\vdash\nu}\qquad
     \prftree{\prfassumption{\alpha\in\Gamma}}
             {\Gamma\vdash\alpha}\qquad
     \prftree{\prfassumption{\beta\in\Gamma}}
             {\Gamma\vdash\beta}\qquad
     \prftree{\prfassumption{N\in\Gamma}}
             {\Gamma\vdash\texttt{typeof}(N)} $$
  $$ \prftree{\prfassumption{\Gamma\vdash\tau_i\ \forall i}}
             {\Gamma\vdash(\tau_i)}\qquad
     \prftree{\prfassumption{\Gamma\vdash\tau_a}}{\prfassumption{\Gamma\vdash\tau_b}}
             {\Gamma\vdash\tau_a\rightarrow\tau_b} $$
  $$ \prftree{\prfassumption{\forall i,j:C_i=C_j\Rightarrow i=j}}
             {\prfassumption{\Gamma\vdash\tau_i\ \forall i}}
             {\Gamma\vdash\sum_i C_i\tau_i}\qquad
     \prftree{\prfassumption{\forall i,j:l_i=l_j\Rightarrow i=j}}
             {\prfassumption{\Gamma\vdash\tau_i\ \forall i}}
             {\Gamma\vdash\{l_i:\tau_i\}} $$
  $$ \prftree{\prfassumption{\Gamma,\alpha\vdash\tau}}
             {\Gamma\vdash\forall\alpha.\tau} $$
  \caption{Well-formed contexts and types}
  \label{f:ctxt}
\end{figure}

\todo{adding paths and path resolution.}

Figures~\ref{f:subtyping1} and \ref{f:subtyping2} shows the
polymorphic subtyping relation in Parsley, deriving from the worklist
approach of in~\cite{zhao2018,zhao19:bidir}.  This has a simpler
presentation than the one in~\cite{Dunfield13:bidir} since it does not
use output contexts, and has the advantage of being formally verified.
In this approach, the worklist $\Omega$ represents a list of
outstanding subtyping judgments of the form $\sigma_1\leq\sigma_2$.
Each rule takes the judgment at the head of the worklist, either
solves it or breaks into smaller judgments that it pushes onto the
worklist, and repeats until the worklist is empty.  In order to solve
for unknown types, the process introduces {\em existential type
  variables} $\beta$ into the context, and when such a variable is
solved, the solution is immediately substituted into the worklist
before proceeding.

\begin{figure}
  $$ \boxed{\Gamma\vdash\Omega} $$
  $$ $$
  $$ \prfaxiom{\Gamma\vdash\cdot} $$
  $$ \prftree{\prfassumption{\Gamma\vdash\Omega}}
             {\prfassumption{\Gamma\vdash\nu\leq\nu;\Omega}}\qquad
     \prftree{\prfassumption{\alpha\in\Gamma}}
             {\prfassumption{\Gamma\vdash\Omega}}
             {\Gamma\vdash\alpha\leq\alpha;\Omega}\qquad
     \prftree{\prfassumption{\beta\in\Gamma}}
             {\prfassumption{\Gamma\vdash\Omega}}
             {\Gamma\vdash\beta\leq\beta;\Omega} $$
  $$ \prftree{\prfassumption{\texttt{len}(\tau_i)=\texttt{len}(\tau'_i)}}
             {\prfassumption{\Gamma\vdash[\tau_i\leq\tau'_i\ \forall i];\Omega}}
             {\Gamma\vdash(\tau_i)\leq(\tau'_i);\Omega} $$
  $$ \prftree{\prfassumption{\forall i:C_i=C'_i}}
             {\prfassumption{\Gamma\vdash[\tau_i\leq\tau'_i\ \forall i];\Omega}}
             {\Gamma\vdash(\sum_iC_i\tau_i\leq\sum_iC'_i\tau'_i);\Omega}\qquad
     \prftree{\prfassumption{\forall i:l_i=l'_i}}
             {\prfassumption{\Gamma\vdash[\tau_i\leq\tau'_i\ \forall i];\Omega}}
             {\Gamma\vdash(\{l_i:\tau_i\}\leq\{l'_i:\tau'_i\});\Omega} $$
  $$ \prftree{\prfassumption{N:\{l_i:\tau_i\}\in\Gamma}}
             {\prfassumption{\Gamma\vdash\{l_i:\tau_i\}\leq\sigma};\Omega}
             {\Gamma\vdash\texttt{typeof}(N)\leq\sigma;\Omega}\qquad
     \prftree{\prfassumption{N:\{l_i:\tau_i\}\in\Gamma}}
             {\prfassumption{\Gamma\vdash\sigma\leq\{l_i:\tau_i\};\Omega}}
             {\Gamma\vdash\sigma\leq\texttt{typeof}(N);\Omega} $$
  $$ \prftree{\prfassumption{\Gamma\vdash\sigma'_1\leq\sigma_1;\sigma_2\leq\sigma'_2;\Omega}}
             {\Gamma\vdash\sigma_1\rightarrow\sigma_2\leq\sigma'_1\rightarrow\sigma'_2;\Omega} $$
  $$ \prftree{\prfassumption{\texttt{fresh}\ \beta'}}
             {\prfassumption{\Gamma,\beta'\vdash[\beta'/\alpha]\sigma\leq\sigma'}}
             {\Gamma\vdash\forall\alpha.\sigma\leq\sigma'}\qquad
     \prftree{\prfassumption{\texttt{fresh}\ \alpha}}
             {\prfassumption{\Gamma,\alpha\vdash\sigma\leq\sigma'}}
             {\Gamma\vdash\sigma\leq\forall\alpha.\sigma'} $$
  $$ \prftree{\prfassumption{\beta\notin FV(\sigma_1)\cup FV(\sigma_2)}}
             {\prfassumption{\Gamma[\beta_1,\beta_2]\vdash\beta_1\rightarrow\beta_2\leq\sigma_1\rightarrow\sigma_2;[\beta_1\rightarrow\beta_2/\beta]\Omega}}
             {\Gamma[\beta]\vdash\beta\leq\sigma_1\rightarrow\sigma_2;\Omega} $$
  $$ \prftree{\prfassumption{\beta\notin FV(\sigma_1)\cup FV(\sigma_2)}}
             {\prfassumption{\Gamma[\beta_1,\beta_2]\vdash\sigma_1\rightarrow\sigma_2\leq\beta_1\rightarrow\beta_2;[\beta_1\rightarrow\beta_2/\beta]\Omega}}
             {\Gamma[\beta]\vdash\sigma_1\rightarrow\sigma_2\leq\beta;\Omega} $$
  $$ \prftree{\prfassumption{\beta\notin\cup_iFV(\sigma_i)}}
             {\prfassumption{\Gamma[[\beta_i]]\vdash[\beta_i\leq\sigma_i];[(\beta_i)/\beta]\Omega}}
             {\Gamma[\beta]\vdash\beta\leq(\sigma_i);\Omega} $$
  $$ \prftree{\prfassumption{\beta\notin\cup_iFV(\sigma_i)}}
             {\prfassumption{\Gamma[[\beta_i]]\vdash[\sigma_i\leq\beta_i];[(\beta_i)/\beta]\Omega}}
             {\Gamma[\beta]\vdash(\sigma_i)\leq\beta;\Omega} $$
  $$ \prftree{\prfassumption{\beta\notin\cup_iFV(\sigma_i)}}
             {\prfassumption{\Gamma[[\beta_i]]\vdash[\beta_i\leq\sigma_i];[\{l_i:\beta_i\}/\beta]\Omega}}
             {\Gamma[\beta]\vdash\beta\leq\{l_i:\sigma_i\};\Omega} $$
  $$ \prftree{\prfassumption{\beta\notin\cup_iFV(\sigma_i)}}
             {\prfassumption{\Gamma[[\beta_i]]\vdash[\sigma_i\leq\beta_i];[\{l_i:\beta_i\}/\beta]\Omega}}
             {\Gamma[\beta]\vdash\{l_i:\sigma_i\}\leq\beta;\Omega} $$
  $$ \prftree{\prfassumption{\beta\notin\cup_iFV(\sigma_i)}}
             {\prfassumption{\Gamma[[\beta_i]]\vdash[\beta_i\leq\sigma_i];[\sum_iC_i\beta_i/\beta]\Omega}}
             {\Gamma[\beta]\vdash\beta\leq\sum_iC_i\sigma_i;\Omega} $$
  $$ \prftree{\prfassumption{\beta\notin\cup_iFV(\sigma_i)}}
             {\prfassumption{\Gamma[[\beta_i]]\vdash[\sigma_i\leq\beta_i];[\sum_iC_i\beta_i\}/\beta]\Omega}}
             {\Gamma[\beta]\vdash\sum_iC_i\sigma_i\leq\beta;\Omega} $$
  \caption{The algorithmic subtyping relation (part 1)}
  \label{f:subtyping1}
\end{figure}

\begin{figure}
  $$ \boxed{\Gamma\vdash\Omega} $$
  $$ $$
  $$ \prftree{\prfassumption{\Gamma[\beta_1][]\vdash[\beta_1/\beta_2]\Omega}}
             {\Gamma[\beta_1][\beta_2]\vdash\beta_1\leq\beta_2;\Omega}\qquad
     \prftree{\prfassumption{\Gamma[\beta_1][]\vdash[\beta_1/\beta_2]\Omega}}
             {\Gamma[\beta_1][\beta_2]\vdash\beta_2\leq\beta_1;\Omega} $$
  $$ \prftree{\prfassumption{\Gamma[\alpha][]\vdash[\alpha/\beta]\Omega}}
             {\Gamma[\alpha][\beta]\vdash\alpha\leq\beta;\Omega}\qquad
     \prftree{\prfassumption{\Gamma[\alpha][]\vdash[\alpha/\beta]\Omega}}
             {\Gamma[\alpha][\beta]\vdash\beta\leq\alpha;\Omega} $$
  $$ \prftree{\prfassumption{\Gamma[]\vdash[\nu/\beta]\Omega}}
             {\Gamma[\beta]\vdash\nu\leq\beta;\Omega}\qquad
     \prftree{\prfassumption{\Gamma[]\vdash[\nu/\beta]\Omega}}
             {\Gamma[\beta]\vdash\beta\leq\nu;\Omega} $$
  \caption{The algorithmic subtyping relation (part 2)}
  \label{f:subtyping2}
\end{figure}

\section*{Acknowledgments}
This work was supported by DARPA under agreement number HR001119C0075.
The views and conclusions contained herein are those of the authors
and should not be interpreted as necessarily representing the official
policies or endorsements, either expressed or implied, of DARPA or the
U.S. Government.

\bibliographystyle{plain}
\bibliography{parsley}
\end{document}
