\documentclass[letterpaper]{article}

\usepackage{cite}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{amsmath,amsthm,amssymb,mathtools}
\usepackage{prftree}

\usepackage{tikz}
\usetikzlibrary{calc,positioning,fit,shapes}

\newcommand{\todo}[1]{{\color{red}[TODO: #1]}}

% notation
\newcommand{\utv}{\alpha}             % universal type variable
\newcommand{\etv}{{\widehat{\beta}}}  % existential type variable
\newcommand{\stv}{{\grave{\zeta}}}    % substitution type variable

\title{The Parsley Data Definition Language}
\author{The Parsley Team}

\begin{document}
\maketitle

\begin{abstract}
  Any program that reads formatted input relies on parsing software to
  check the input for validity and transform it into a representation
  suitable for further processing.  Many security vulnerabilities can
  be attributed to poorly defined grammars, incorrect parsing, and
  sloppy input validation.  In contrast to the syntax for programming
  languages, grammars for even common data formats such as DNS and PDF
  are typically context-sensitive and heterogenous.  However, as in
  programming languages, a standard notation or {\em language} to
  express these data format grammars can address poor or ambiguous
  definitions, and the automated generation of correct-by-construction
  parsers from such grammar specifications can yield correct and type-
  and memory-safe data parsing routines.

  This document describes the design of Parsley, a declarative data
  format definition language that combines grammars and constraints in
  a modular way.  It describes the syntax, type system and semantics
  of the language.  It will eventually describe its compiler, which
  will generate an executable parsing library from a Parsley
  specification, and other outputs to enable the verification of the
  correctness of generated parser.
\end{abstract}

\section{Language Design}
\label{s:design}

The language has the following design goals:

\begin{itemize}
\item A useful foundational set of parser primitives and combinators,
\item A capacity to capture context-sensitivity and data-dependency
  via a constraint system, and
\item  A module system that enables nested grammars and composes with
  the constraint system.
\end{itemize}

We employ the following techniques to achieve these goals:

\begin{itemize}
\item The core structure of a Parsley specification is provided by a
  {\em parsing expression grammar (PEG)} \cite{ford2004popl},
  specified in notation similar to {\em extended BNF (EBNF)} for
  grammar productions.  Although {\em context-free grammars (CFGs)}
  use the EBNF notation, there are critical differences in the PEG
  notation: (a) the choice combinator in PEGs is ordered, as opposed
  to non-deterministic in CFGs, and (b) the PEG notation includes
  syntactic predicates that do not occur in CFGs.  The choice of a PEG
  core provides us a core set of primitives and combinators we can
  build on.

\item Context management is provided by a fairly traditional
  attribute-grammar system, where the expression language for
  attribute computations is purely functional and strongly-typed.  In
  Parsley, non-terminals have user-defined attributes, while terminals
  have a default attribute value of type byte or byte-string.  This
  provides us with the tools needed to capture context-sensitivity.

\item Additional context-sensitivity is provided by a constraint
  system that guards further processing within a non-terminal
  production.  The constraint language uses the attribute system to
  perform context-sensitive checks, and cleanly enables data-dependent
  parsing.

\item A module system allows the composition of independent grammars.
\end{itemize}

The expression sublanguage used in attribute updates and constraints
is a strongly typed polymorphic functional language supporting
user-defined types and functions.  It includes a standard library of
common types and utility functions.  The expression and data type
sublanguage is designed to ensure that recursive and iterative
computations always terminate.

\section{Language Use}
\label{s:use}

\begin{figure*}[!ht]
  \centering
  \resizebox{10cm}{!}{\input{figs/parsley-pipeline-tikz}}
  \caption{Parsley in context.}
  \label{f:pipeline}
\end{figure*}

The typical use of a Parsley specification is via the workflow
illustrated in Figure~\ref{f:pipeline}.

The Parsley compiler performs type and semantic checks on a given
Parsley specification.  The type checks correspond to standard
polymorphic type checking~\cite{Dunfield13:bidir}\cite{zhao19:bidir},
with rules to handle grammar productions.  In addition, attribute
usage checks are performed, such as for $L$-attributedness (see
below).

The compiler generates prover definitions that are used to perform
safety checks: for example, a check to ensure that data-dependent
constructs do not use a data value as an array index without an
appropriate constraint check.  We are developing the safety properties
that can be used by the PVS theorem prover to verify that the Parsley
specification is a `safe' grammar.

We are also defining the parsing automaton that will be generated by
the compiler.  This automaton needs to interleave constraint and
attribute computation with parsing actions that construct the internal
data representation and manipulate the parsing buffer.  When used for
efficiently parsing data, especially network protocols, attribute
computations have to be done on partially constructed parse trees
(unlike the typical use of attribute grammars in programming
languages, where the entire parse tree of a program can be available
before processing).  In our experience of using Parsley to define data
formats, the computations in constraints and attribute updates require
access to a parsing context (via inherited attributes) that is best
handled by $L$-attributed grammars, which are compatible with the
top-down processing of the ``core'' PEG specification.  $L$-attributed
grammars are attribute grammars where attributes in the nodes in the
parse tree to the left of the current node have been assigned their
final values.  This eases the implementation of PEG backtracking, as
assigned attribute values do not need to be unwound.  The generated
automaton is compiled into a library that can be linked into
application code.  We plan to use a Rust code generator to ensure that
the library is type and memory safe, can be linked into C
applications, and is compatible with other languages using the
appropriate wrappers.

The data representation constructed by the automaton contains a {\em
  proof of parse}.  We are building on the approach used in
~\cite{Blaudeau_2020}, which formalized PEG parsing and the generation
of verifiable PEG parsers.  These parsers annotate the constructed
data representation with grammar metadata that can be used to verify
that the representation is a valid parse of the given input data for
the given Parsley specification.  This verification is done in an
independent verifier, which is simple enough to include in the
application itself.

\subsection*{Unresolved issues}

The API between the application and the parsing library will dictate
crucial implementation choices, and hence impact the code generation
pipeline.  This API might differ across applications parsing the same
format, and these types of API often differ across different types of
formats (e.g. streaming network formats versus document formats).

A crucial requirement is to ensure that the parsing automaton is not
Turing-complete; i.e. arbitrary input data cannot cause
Turing-complete computation within the parsing library.  We are
attempting to provide formal guarantees that this will be the case.

\section{Abstract syntax}
\label{s:syntax}

The abstract syntax of Parsley is shown in
Figure~\ref{f:parsley-syntax}, and has two layers: the expression
sublanguage is shown first, followed by the grammar sublanguage.

\begin{figure}
  \begin{tabular}{l c l l}
    Paths        & $p$      & ::= & $ x \mid p.x $ \\
    Constants    & c        & ::= & 0,1,\ldots\ $|$\ `A', `B', \ldots\ $|$\ \ldots \\
    Constructors & C        &     & \\
    Attributes   & $l$      & ::= & $ l^i \mid l^s $ \\
    Base types   & $\nu$    & ::= & $ \texttt{unit} \mid \texttt{uint8} \mid \texttt{int32} \mid \ldots $ \\
    Monotypes    & $\tau$   & ::= & $ \utv \mid \nu \mid (\tau_i) \mid \tau\rightarrow\tau \mid \sum_i C_i\tau_i \mid \{l_i:\tau_i\} \mid \texttt{typeof}(N) $ \\
    Types        & $\sigma$ & ::= & $ \tau \mid \forall\utv.\sigma \mid \sigma\rightarrow\sigma $ \\
    Expressions  & $e$      & ::= & $ p \mid \textrm{c} \mid C e \mid (e_i) \mid e\ e \mid e\ \texttt{op}\ e \mid (e : \tau) \mid e.l $ \\
                 &          &     & $\mid \textrm{case }e\ \{\rho_i, e_i\} \mid \textrm{let }x=e\textrm{ in }e \mid e \sim C \mid f\ e $ \\
    Patterns     & $\rho$   & ::= & $ x \mid (\rho_i) \mid C\rho $ \\ % TODO: record patterns
    Functions    & $f$      & ::= & $ f := (x_i:\sigma_i)\rightarrow\sigma \{e\} $ \\
    Statements   & $s$      & ::= & $ p = e $ \\
                 &          &     & \\
    Constraints  & $\phi$   & ::= & $ e $ \\
    Actions      & $a$      & ::= & $ \{s_i\} $ \\
    Rules        & $r$      & ::= & $ \epsilon \mid \textrm{c} \mid (x=)^?N\{l_i=e_i\} \mid \phi r $ \\
                 &          &     & $\mid r r \mid r / r \mid r^{*e?} \mid !r \mid !^Rr \mid a $ \\
    Productions  & $P$      & ::= & $ N\{l_i:\tau_i\} := r $ \\
    Format       & $F$      & ::= & $ \{ \tau_i, N\{l_i:\tau_i\}, P_i \} $ \\
  \end{tabular}
  \caption{Abstract syntax of the Parsley specification language}
  \label{f:parsley-syntax}
\end{figure}

\subsection*{Expression sublanguage}
\label{ss:lang:expr}

In Figure~\ref{f:parsley-syntax}, $x$ over identifiers, $l$ over
inherited $l^i$ and synthesized $l^s$ attributes, $\utv$ ranges over
type variables, and $op$ over standard arithmetic and boolean
operators.  Paths $p$ are used to access identifiers across modules.

The type system is a conventional polymorphic type system
with records.  It is equipped with a set of standard base types $\nu$, type
constructors like tuples $(\tau_i)$, functions $\tau\rightarrow\tau$,
sums $\sum_iC_i\tau_i$, records $\{l_i:\tau_i\}$ and
polymorphic type schemes $\forall\utv.\tau$.  The Parsley library
defines standard data types such as polymorphic lists, sets, and maps.

The expression language is also standard, with tuples $(e_i)$, sums
$C_i e_i$, function application $e\ e$, attribute or record field
selection $e.l$, type constraints $(e:\tau)$, and let bindings and
case expressions that bind patterns within expressions.  The
$e\ \sim\ C$ is a boolean expression that tests if $e$ is a sum with
the $C$ constructor; this is a useful primitive within grammar
constraints.

Parsley supports user-defined higher-ranked polymorphic functions $f$,
where the function arguments have polymorphic types.  The supporting
type system is described in \S\ref{s:typesys}.

Statements are the only imperative constructs, and consist of
assignments to (synthesized) attributes.

\subsection*{Grammar sublanguage}
\label{ss:lang:grammar}

We now come to the grammatical constructions: productions, rules, and
actions.  These are based on parsing expression grammars (PEGs)
\cite{ford2004popl}, but are extended with an attribute system and
constraints to capture context sensitivity.  A grammar production
defines the parsing expression for a non-terminal $N$.  Each $N$ is
typed as a record named $\texttt{typeof}(N)$ with its attributes as
the record fields.  Rules $r$ are elemental parsing expressions and
are combined with parsing combinators.  Actions $a$ are used to update
parsing state during parsing, and consist of a sequence of statements
where synthesized attributes are assigned.  The primitive rules are
$\epsilon$, which successfully matches without consuming any input,
and literals $\textrm{c}$, which match if the input has a $c$ prefix,
upon which that prefix is consumed.  The $N\{l_i=e_i\}$ rule matches
if its production matches an input prefix given its inherited
attributes $l_i$ are initialized as specified with expressions $e_i$
evaluated within the parsing context at that point.  The $x=N$
construct names the matched value (of type $\texttt{typeof}(N)$), and
enables access to the values of its attributes as $x.l$ in expressions
appearing within any subsequent constraints, actions, or attribute
initializations.

These primitive rules can be combined with combinators, as in PEG, but
with some extensions.  $r\ r$ denotes the PEG sequence operator, while
$r\ /\ r$ is the PEG ordered choice.  The $!r$ construct is the
\emph{not} syntactic predicate in PEG.  $r^{*e?}$ denotes the Kleene
star, but with an optional bound $e$ that is context sensitive.  If
the bound is present, it limits the number of times that $r$ is
matched.

A parsing rule $r$ can be guarded with a constraint expression $\phi$,
written as $\phi\ r$: the boolean expression $\phi$ is evaluated
before deciding to proceed parsing with rule $r$.  This is a Parsley
extension of PEG, and could be thought of as a \emph{contextual}
predicate: $\phi$ can check the current parsing state, using the
attribute values of syntactic elements in its context.  If this guard
fails, parsing backtracks to the most recent choice point, and
continues with the next alternative.

Parsley is equipped with a module system that enables splitting a
specification into multiple files, and allows data specifications to
be re-used in different contexts.  Paths support the module system
(not shown) by enabling cross-module use of types and syntax elements.

\subsection*{Extensions under development}

The Parsley language is a work-in-progress, and is being adapted as we
attempt to use it to capture more data formats.  The parsing of a PDF
file involves seeking to the end of the file (or a specific marker)
and searching backwards for a syntactic element.  This motivated the
$!^Rr$ construct, which can be considered as a \emph{reverse-not}
predicate: it checks backwards from the current parsing location
whether the parse buffer matches $r$.

We are also considering extending Parsley with primitives to capture
manipulations of the current parsing offset by actions such as
seeking.  Such offset manipulation could either derive declaratively
from the format specification, or procedurally under the control of
the application driving the parser.  A design challenge is to ensure
both types of manipulations are supported and compose well.  In
addition, this is one of the most security-critical aspects of
parsing: ensuring that offsets derived from untrusted data are used in
valid ways.

\section{Type system}
\label{s:typesys}

The polymorphic type system used in Parsley supports higher-ranked
polymorphism with type-inference, using a bidirectional scheme based
on~\cite{Dunfield13:bidir}.  It requires type annotations for
polymorphic function arguments, and allows only predicative type
inference.  This system relies on a standard polymorphic subtyping
scheme \cite{odersky96} to guide instantiation of polymorphic
quantifiers.  We extend this system to the Parsley grammar language as
described below.

\begin{figure}
  \begin{tabular}{l c l l l}
    Existential variables & $\etv$   &     &                                   & \\
    Inference variables   & $\stv$   &     &                                   & \\
    Monotypes             & $\tau$   & ::= & $ \utv\ \ldots $                  & as in Figure~\ref{f:parsley-syntax} \\
    Algorithmic types     & $\sigma$ & ::= & $ \etv \mid \stv $                & \\
                          &          &     & $ \mid \tau\ \ldots $             & as in Figure~\ref{f:parsley-syntax} \\
                          &          &     &                                   & \\
    Judgment              & $\iota$  & ::= & $ \sigma_1\leq\sigma_2 $          & subtyping judgment \\
                          &          &     & $ e\Leftarrow\sigma $             & checking judgment \\
                          &          &     & $ \mathrm{cover}(\{\rho_i\}, \tau) $ & pattern check \\

                          &          &     &                                   & \\
    Judgment chain        & $\omega$ & ::= & $ \iota $                         & single judgment \\
                          &          &     & $ \iota, \omega $                 & judgment sequence \\
                          &          &     & $ e\Rightarrow_\etv\omega $       & type inference \\
                          &          &     & $ \sigma\bullet e\rightsquigarrow_\stv\omega $  & application inference \\
                          &          &     & $ (\{\rho_i\},\tau)\Rightarrow_\stv\omega $     & pattern type refinement \\
                          &          &     & $ (\rho,\tau)\oplus e\Rightarrow_\stv\omega $   & patterned type inference \\
                          &          &     &                                   & \\
    Worklist              & $\Gamma$ & ::= & $ \cdot $                         & empty context \\
                          &          &     & $ \mid\Gamma, C: \sigma$          & value constructor \\
                          &          &     & $ \mid\Gamma, l: \sigma$          & record destructor \\
                          &          &     & $ \mid\Gamma, x: \tau $           & program variable \\
                          &          &     & $ \mid\Gamma, N: \{l_i:\tau_i\} $ & non-terminal \\
                          &          &     & $ \mid\Gamma, \utv $              & universal type variable \\
                          &          &     & $ \mid\Gamma, \etv  $             & existential type variable\\
                          &          &     & $ \mid\Gamma\Vdash\omega $        & judgment work \\

  \end{tabular}
  \caption{Entities in the Parsley type-checking algorithm}
  \label{f:ts:defs}
\end{figure}

The presentation of the Parsley type system follows the worklist
approach of~\cite{zhao2018,zhao19:bidir}, which provides convenient
scoping of type variables introduced during type-checking, with a few
differences explained below.  Figure~\ref{f:ts:defs}
describes the basic entities and their well-formedness criteria.
Existential type variables $\etv$ are introduced to solve for types
that need to be guessed in the declarative system
of~\cite{Dunfield13:bidir}.

Parsley also adds inference type variables $\stv$ represent the types
generated by the inference judgments described below, and are
essentially location markers within judgments where inferred types
need to be substituted once they are known.  Crucially, these
variables do not appear in the bindings of the worklist context, and
when judgments are checked, they cannot contain these inference type
variables since they should have been substituted away.  The monotypes
$\tau$ of Figure~\ref{f:parsley-syntax} are extended with these two
type variables.\footnote{Substitution type variables and universal
  type variables are not differentiated
  in~\cite{zhao2018,zhao19:bidir}; both are represented with the same
  notation.  We find that explicitly clarifying their difference helps
  avoid confusion and resulting bugs in an executable implemention of
  the typing algorithm.}

The basic checking judgments $\iota$ are the standard subtyping
judgment $\sigma_1\leq\sigma_2$, that checks whether $\sigma_1$ is a
subtype of $\sigma_2$, the type checking judgment $e\Leftarrow\sigma$
that checks that the expression $e$ has the type $\sigma$, and the
pattern check judgment $\mathrm{cover}(\{\rho_i\},\tau$ that checks
that the patterns $\{\rho_i\}$ form an exhaustive but non-redundant
match for the forms of the values of $\tau$.

The typing algorithm collects pending judgments into judgment chains
$\omega$, which are sequences of basic judgments $\iota$ or inference
judgments.  The type inference judgment $e\Rightarrow_\stv\omega$
synthesizes the type of $e$ and substitutes that for $\stv$ within the
judgment chain $\omega$.  The application inference judgment
$\sigma\bullet e\rightsquigarrow_\stv\omega$ synthesizes the type of
the application of a function of type $\sigma$ to the argument $e$ and
substitutes that result type for $\stv$ within $\omega$.

Parsley adds additional inference judgments to handle pattern
matching.  The pattern type refinement
$(\{\rho_i\},\tau)\Rightarrow_\stv\omega$ specializes $\tau$ given
that the patterns $\{\rho_i\}$ are supposed to match it, and
substitutes that specialized result for $\stv$ within $\omega$.  The
patterned type inference judgment $(\rho,\tau)\oplus e\Rightarrow_\stv\omega$
matches the pattern $\rho$ to type $\tau$ to
give the types for the binding variables within $\rho$, extends the
typing context with those variable bindings to infer the type of $e$,
and substitutes that inferred type for $\stv$ within $\omega$.

The worklist $\Gamma$ has the constituents of a traditional typing
context, with bindings for value constructors $C:\sigma$, record
fields $l:\sigma$, program variables $x:\tau$, universal type
variables $\utv$, and existential type variables $\etv$.  Parsley also
adds the types of non-terminals $N$, which are represented by record
types.  In addition, $\Gamma$ contains embedded judgment chains
$\omega$ that need to be checked within their preceding contexts.
This is the key to simplifying the binding context management for the
type checking algorithm.  Note that $\Gamma$ does not contain
substitution type variables $\stv$, as explained earlier.

Figure~\ref{f:ts:wf} shows the mutually recursive rules for
well-formedness of these entities of the type system.  Note that
substitution variables are substituted away when checking for
well-formed judgment chains $\Gamma\Vdash\omega$.

\begin{figure}
  $$ \boxed{\vdash\Gamma}\ \textrm{Well-formed worklist} $$
  $$ \prfbyaxiom{$\mathtt{wf_w\cdot}$}{\Vdash\cdot}\qquad
     \prftree[r]{$\mathtt{wf_w uvar}$}
             {\prfassumption{\utv\notin\Gamma}}
             {\vdash\Gamma, \utv}\qquad
     \prftree[r]{$\mathtt{wf_w evar}$}
             {\prfassumption{\etv\notin\Gamma}}
             {\vdash\Gamma, \etv}\qquad
     \prftree[r]{$\mathtt{wf_w pvar}$}
             {\prfassumption{x\notin\Gamma}}{\prfassumption{\Gamma\vdash\sigma}}
             {\vdash\Gamma, x:\sigma} $$
  $$ \prftree[r]{$\mathtt{wf_w N}$}
             {\prfassumption{N\notin\Gamma}}{\prfassumption{\Gamma\vdash\{l_i:\tau_i\}}}
             {\vdash\Gamma, N:\{l_i:\tau_i\}}\qquad
     \prftree[r]{$\mathtt{wf_\omega}$}
             {\prfassumption{\vdash\Gamma}}{\prfassumption{\Gamma\vdash\omega}}
             {\vdash\Gamma\Vdash\omega} $$

  $$ \boxed{\Gamma\vdash\sigma}\ \textrm{Well-formed type}  $$
  $$ \prfbyaxiom{$\mathtt{wf_t \nu}$}{\Gamma\vdash\nu}\qquad
     \prftree[r]{$\mathtt{wf_t tvar}$}
             {\prfassumption{\utv\in\Gamma}}
             {\Gamma\vdash\utv}\qquad
     \prftree[r]{$\mathtt{wf_t evar}$}
             {\prfassumption{\etv\in\Gamma}}
             {\Gamma\vdash\etv}\qquad
     \prftree[r]{$\mathtt{wf_t typeof}$}
             {\prfassumption{N\in\Gamma}}
             {\Gamma\vdash\texttt{typeof}(N)} $$
  $$ \prftree[r]{$\mathtt{wf_t \forall}$}
             {\prfassumption{\Gamma,\utv\vdash\sigma}}
             {\Gamma\vdash\forall\utv.\sigma}\qquad
     \prftree[r]{$\mathtt{wf_t \rightarrow}$}
             {\prfassumption{\Gamma\vdash\sigma_1}}{\prfassumption{\Gamma\vdash\sigma_2}}
             {\Gamma\vdash\sigma_1\rightarrow\sigma_2}\qquad
     \prftree[r]{$\mathtt{wf_t tup}$}
             {\prfassumption{\Gamma\vdash\tau_i\ \forall i}}
             {\Gamma\vdash(\tau_i)} $$
  $$ \prftree[r]{$\mathtt{wf_t sum}$}
             {\prfassumption{\forall i,j:C_i=C_j\Rightarrow i=j}}
             {\prfassumption{\Gamma\vdash\tau_i\ \forall i}}
             {\Gamma\vdash\sum_i C_i\tau_i}\qquad
     \prftree[r]{$\mathtt{wf_t rec}$}
             {\prfassumption{\forall i,j:l_i=l_j\Rightarrow i=j}}
             {\prfassumption{\Gamma\vdash\tau_i\ \forall i}}
             {\Gamma\vdash\{l_i:\tau_i\}} $$

  $$ \boxed{\Gamma\vdash\omega}\ \textrm{Well-formed judgment} $$
  $$ \prftree[r]{$\mathtt{wf_\omega \leq}$}
             {\prfassumption{\Gamma\vdash\sigma_1}}{\prfassumption{\Gamma\vdash\sigma_2}}
             {\Gamma\vdash\sigma_1\leq\sigma_2}\qquad
     \prftree[r]{$\mathtt{wf_\omega\Leftarrow}$}
             {\prfassumption{\Gamma\vdash e}}{\prfassumption{\Gamma\vdash\sigma}}
             {\Gamma\vdash e\Leftarrow\sigma}\qquad
     \prftree[r]{$\mathtt{wf_\omega\Rightarrow}$}
             {\prfassumption{\Gamma\vdash e}}{\prfassumption{\Gamma,\etv\vdash[\etv/\stv]\omega}}
             {\Gamma\vdash e\Rightarrow_\stv\omega} $$
  $$ \prftree[r]{$\mathtt{wf_\omega cover}$}
             {\prfassumption{\Gamma\vdash\rho_i\ \forall i}}
             {\prfassumption{\Gamma\vdash\tau}}
             {\Gamma\vdash\mathrm{cover}(\{\rho_i\}, \tau)}\qquad
     \prftree[r]{$\mathtt{wf_\omega seq}$}
             {\prfassumption{\Gamma\vdash\iota}}
             {\prfassumption{\Gamma\vdash\omega}}
             {\Gamma\vdash\iota,\omega} $$
  $$ \prftree[r]{$\mathtt{wf_\omega \rightsquigarrow_\stv}$}
             {\prfassumption{\Gamma\vdash\sigma}}{\prfassumption{\Gamma\vdash e}}
             {\prfassumption{\Gamma,\etv\vdash[\etv/\stv]\omega}}
             {\Gamma\vdash\sigma\bullet e\rightsquigarrow_\stv\omega}\qquad
     \prftree[r]{$\mathtt{wf_\omega (\{\rho_i\},\tau)}$}
             {\prfassumption{\Gamma\vdash\rho_i\ \forall i}}
             {\prfassumption{\Gamma\vdash\tau}}
             {\prfassumption{\Gamma,\etv\vdash[\etv/\stv]\omega}}
             {\Gamma\vdash(\{\rho_i\},\tau)\Rightarrow_\stv\omega} $$
  $$ \prftree[r]{$\mathtt{wf_\omega \oplus}$}
             {\prfassumption{\Gamma\vdash\rho}}
             {\prfassumption{\Gamma\vdash\tau}}
             {\prfassumption{\Gamma\vdash\ e}}
             {\Gamma\vdash(\rho,\tau)\oplus e\Rightarrow_\stv\omega} $$
  \caption{Well-formed types, judgments and worklists}
  \label{f:ts:wf}
\end{figure}

Figure~\ref{f:wf:expressions} shows the standard rules for well-formed
patterns and expressions.  The set of binding variables in a pattern
$\rho$ is denoted by $\mathrm{binders}(\rho)$.  Well-formed patterns
are linear, and the $\mathtt{wf_\rho tup}$ rule ensures that all
variables bound by a pattern are distinct.  In the $\mathtt{wf_e
  case}$ rule, the construct $\overline{\mathtt{binders}(\rho)}$ pairs
each pattern variable with a fresh existential variable, providing an
ordered list of variable bindings with which to extend the context
$\Gamma$.

\begin{figure}
  $$ \boxed{\Gamma\vdash \rho}\ \textrm{Well-formed patterns} $$
  $$ \prfbyaxiom{$\mathtt{wf_\rho var}$}
             {\Gamma\vdash x}\qquad
     \prftree[r]{$\mathtt{wf_\rho tup}$}
             {\prfassumption{\Gamma\vdash\rho_i\ \forall i}}
             {\prfassumption{\{\cup_i\mathrm{binders}(\rho_i)\}\textrm{ distinct}}}
             {\Gamma\vdash (\rho_i)}\qquad
     \prftree[r]{$\mathtt{wf_\rho C}$}
             {\prfassumption{C\in\Gamma}}{\prfassumption{\Gamma\vdash\rho}}
             {\Gamma\vdash C\rho} $$
  $$ \boxed{\Gamma\vdash e}\ \textrm{Well-formed expressions} $$
  $$ \prftree[r]{$\mathtt{wf_e pvar}$}
             {\prfassumption{x:\sigma\in\Gamma}}
             {\Gamma\vdash x}\qquad
     \prfbyaxiom{$\mathtt{wf_e \nu}$}
             {\Gamma\vdash \textrm{c}}\qquad
     \prftree[r]{$\mathtt{wf_e app}$}
             {\prfassumption{\Gamma\vdash e_1}}{\prfassumption{\Gamma\vdash e_2}}
             {\Gamma\vdash e_1\ e_2} $$
  $$ \prftree[r]{$\mathtt{wf_e tup}$}
             {\prfassumption{\Gamma\vdash e_i\ \forall i}}
             {\Gamma\vdash (e_i)}\qquad
     \prftree[r]{$\mathtt{wf_e anno}$}
             {\prfassumption{\Gamma\vdash e}}{\prfassumption{\Gamma\vdash\tau}}
             {\Gamma\vdash (e : \tau)}\qquad
     \prftree[r]{$\mathtt{wf_e op}$}
             {\prfassumption{\Gamma\vdash e_1}}{\prfassumption{\Gamma\vdash e_2}}
             {\Gamma\vdash e_1\ \texttt{op}\ e_2} $$
  $$ \prftree[r]{$\mathtt{wf_e attr}$}
             {\prfassumption{\Gamma\vdash e}}{\prfassumption{l\in\Gamma}}
             {\Gamma\vdash e.l}\qquad
     \prftree[r]{$\mathtt{wf_e sum}$}
             {\prfassumption{C\in\Gamma}}{\prfassumption{\Gamma\vdash e}}
             {\Gamma\vdash C e}\qquad
     \prftree[r]{$\mathtt{wf_e match}$}
             {\prfassumption{\Gamma\vdash C}}{\prfassumption{\Gamma\vdash e}}
             {\Gamma\vdash e \sim C} $$
  $$ \prftree[r]{$\mathtt{wf_e case}$}
             {\prfassumption{\Gamma\vdash e}}{\prfassumption{\Gamma\vdash\rho_i\ \forall i}}
             {\prfassumption{\Gamma\,@\,\overline{\mathrm{binders}(\rho_i)}\vdash e_i\ \forall i}}
             {\Gamma\vdash\textrm{case}\ e\ \{\rho_i, e_i\}} $$
  $$ \prftree[r]{$\mathtt{wf_e let}$}
             {\prfassumption{\Gamma\vdash e_1}}{\prfassumption{\Gamma\vdash\rho}}
             {\prfassumption{\Gamma\,@\,\overline{\mathrm{binders}(\rho)}\vdash e_2}}
             {\Gamma\vdash\textrm{let}\ \rho=e_1\ \textrm{in}\ e_2} $$
  $$ \prftree[r]{$\mathtt{wf_e fapp}$}
             {\prfassumption{f:(\sigma_i)\rightarrow\sigma\in\Gamma}}
             {\prfassumption{\Gamma\vdash e_i\ \forall i}}
             {\prfassumption{\mathrm{len}(\sigma_i) = \mathrm{len}(e_i)} = n}
             {\Gamma\vdash f e_1 \ldots e_n} $$
  \caption{Well-formed expressions}
  \label{f:wf:expressions}
\end{figure}

\todo{adding paths and path resolution.}

Figures~\ref{f:typecheck:std} and ~\ref{f:typecheck:parsley} show the
typing rules for Parsley, deriving again from the worklist approach
of~\cite{zhao2018,zhao19:bidir}.  The main typing rules take the
judgment at the head of the worklist, and either solve it or break it
into smaller judgments that are pushed onto the worklist; this repeats
until the worklist is empty.  In order to solve for unknown types, the
process introduces {\em existential type variables} $\etv$ into the
context, and when such a variable is solved, the solution is
immediately substituted into the worklist before proceeding.

%\newcommand\rstep[1]{~\longrightarrow_{\makebox[0pt][l]{$\scriptstyle #1$}\phantom{~~}}}
\newcommand\rstep[1]{~\longrightarrow}
\newcounter{ruleCounter}
\newcommand\typrule{\refstepcounter{ruleCounter}\rstep{\arabic{ruleCounter}}}

\begin{figure}
  $$ \boxed{\Gamma\vdash\Gamma'}\ \textrm{$\Gamma$ reduces to $\Gamma'$} $$
  \begin{align}
    \Gamma,a    &\typrule \Gamma \qquad
    \Gamma,\utv  \typrule \Gamma \qquad
    \Gamma,\etv  \typrule \Gamma        \label{typ:gc}
    \\
    \Gamma\Vdash \nu\leq\nu   &\typrule \Gamma \label{typ:solve:trivial:start} \\
    \Gamma\Vdash \utv\leq\utv &\typrule \Gamma \\
    \Gamma\Vdash \etv\leq\etv &\typrule \Gamma \label{typ:solve:trivial:end} \\
    \Gamma\Vdash \sigma_1\rightarrow\sigma_2\leq \sigma'_1\rightarrow\sigma'_2
      &\typrule \Gamma\Vdash\sigma_2\leq\sigma'_2\Vdash\sigma'_1\leq\sigma_1 \\
    \Gamma\Vdash \forall\utv.\sigma\leq\sigma'
      &\typrule \Gamma,\etv\Vdash [\etv/\utv]\sigma\leq\sigma' \quad\text{when } \sigma'\neq\forall\utv.\sigma'' \\
    \Gamma\Vdash \sigma\leq\forall\utv.\sigma'
      &\typrule \Gamma,\utv\Vdash \sigma\leq\sigma' \\
    \Gamma[\etv]\Vdash \etv\leq\sigma\rightarrow\sigma'
      &\typrule [\etv_1\rightarrow\etv_2/\etv](\Gamma[\etv_1,\etv_2]\Vdash
                               \etv_1\rightarrow\etv_2\leq\sigma\rightarrow\sigma') \notag\\
      &\qquad\qquad\text{when }\etv\notin FV(\sigma)\cup FV(\sigma') \\
    \Gamma[\etv]\Vdash \sigma\rightarrow\sigma'\leq\etv
      &\typrule [\etv_1\rightarrow\etv_2/\etv](\Gamma[\etv_1,\etv_2]\Vdash
                               \sigma\rightarrow\sigma'\leq\etv_1\rightarrow\etv_2) \notag\\
      &\qquad\qquad\text{when }\etv\notin FV(\sigma)\cup FV(\sigma') \\
    \Gamma[\etv][\etv']\Vdash \etv\leq\etv' &\typrule [\etv/\etv'](\Gamma[\etv][]) \\
    \Gamma[\etv][\etv']\Vdash \etv'\leq\etv &\typrule [\etv/\etv'](\Gamma[\etv][]) \\
    \Gamma[\utv][\etv]\Vdash \utv\leq\etv &\typrule [\utv/\etv](\Gamma[\utv][]) \\
    \Gamma[\utv][\etv]\Vdash \etv\leq\utv &\typrule [\utv/\etv](\Gamma[\utv][]) \\
    \Gamma[\etv]\Vdash \nu\leq\etv &\typrule [\nu/\etv](\Gamma[]) \\
    \Gamma[\etv]\Vdash \etv\leq\nu &\typrule [\nu/\etv](\Gamma[]) \\
    \Gamma\Vdash e\Leftarrow\sigma
      &\typrule \Gamma\Vdash e\Rightarrow_\stv \stv\leq\sigma \quad\text{when $\sigma\neq\forall\utv.\sigma'$} \\
    \Gamma\Vdash e\Leftarrow\forall\utv.\sigma
      &\typrule \Gamma,\utv\Vdash e\Leftarrow\sigma \\
    \Gamma\Vdash x\Rightarrow_\stv\omega
      &\typrule \Gamma\Vdash [\sigma/\stv]\omega \quad\text{when $x:\sigma\in\Gamma$} \\
    \Gamma\Vdash (e : \sigma)\Rightarrow_\stv\omega
      &\typrule \Gamma\Vdash[\sigma/\stv]\omega\Vdash e\Leftarrow\sigma \\
    \Gamma\Vdash \mathrm{c}\Rightarrow_\stv\omega
      &\typrule \Gamma\Vdash[\nu/\stv]\omega \\
    \Gamma\Vdash e_1\ e_2\Rightarrow_\stv\omega
      &\typrule \Gamma\Vdash e_1\Rightarrow_{\stv'}(\stv'\bullet e_2\rightsquigarrow_\stv\omega) \\
    \Gamma\Vdash \forall\utv.\sigma\bullet e\rightsquigarrow_\stv\omega
      &\typrule \Gamma,\etv\Vdash[\etv/\utv]\sigma\bullet e\rightsquigarrow_\stv\omega \\
    \Gamma\Vdash \sigma\rightarrow\sigma'\bullet e \rightsquigarrow_\stv\omega
      &\typrule \Gamma\Vdash [\sigma'/\stv]\omega \Vdash e\Leftarrow\sigma \\
    \Gamma[\etv]\Vdash \etv\bullet e\rightsquigarrow_\stv\omega
      &\typrule [\etv_1\rightarrow\etv_2](\Gamma[\etv_1,\etv_2]\Vdash\etv_1\rightarrow\etv_2\bullet e\rightsquigarrow_\stv\omega)
  \end{align}
  \caption{Expression typing rules (standard)}
  \label{f:typecheck:std}
\end{figure}

\begin{figure}
  $$ \boxed{\Gamma\vdash\Gamma'}\ \textrm{$\Gamma$ reduces to $\Gamma'$} $$
  \begin{align}
    \Gamma\Vdash \iota, \omega
      &\typrule \Gamma\Vdash\omega\Vdash\iota \label{typ:seq} \\
    \Gamma\Vdash (\sigma_i)\leq(\sigma'_j)
      &\typrule \Gamma\,@\,\{\Vdash \sigma_i\leq\sigma'_i\}_i \notag\\
      &\qquad\qquad\text{when }\textrm{len}(\sigma_i)=\textrm{len}(\sigma'_j) \\
    \Gamma[\etv]\Vdash \etv\leq(\sigma_i)
      &\typrule [(\etv_i)/\etv](\Gamma[[\etv_i]]\Vdash (\etv_i)\leq(\sigma_i)) \notag\\
      &\qquad\qquad\text{when }\etv\notin\cup_i FV(\sigma_i) \\
    \Gamma[\etv]\Vdash (\sigma_i)\leq\etv
      &\typrule [(\etv_i)/\etv](\Gamma[[\etv_i]]\Vdash (\sigma_i)\leq(\etv_i)) \notag\\
      &\qquad\qquad\text{when }\etv\notin\cup_i FV(\sigma_i) \\
    \Gamma\Vdash \{l_i:\sigma_i\}\leq\{l'_j:\sigma'_j\}
      &\typrule \Gamma\,@\,\{\Vdash \sigma_i\leq\sigma'_i\}_i \notag\\
      &\qquad\qquad\text{when }\{l'_j\}\subseteq\{l_i\} \\
    \Gamma[\etv]\Vdash \etv\leq\{l_i:\sigma_i\}
      &\typrule [\{l_i:\etv_i\}/\etv](\Gamma[[\etv_i]]\Vdash \{l_i:\etv_i\}\leq\{l_i:\sigma_i\}) \notag\\
      &\qquad\qquad\text{when }\etv\notin\cup_i FV(\sigma_i) \\
    \Gamma[\etv]\Vdash \{l_i:\sigma_i\}\leq\etv
      &\typrule [\{l_i:\etv_i\}/\etv](\Gamma[[\etv_i]]\Vdash \{l_i:\sigma_i\}\leq\{l_i:\etv_i\}) \notag\\
      &\qquad\qquad\text{when }\etv\notin\cup_i FV(\sigma_i) \\
    \Gamma\Vdash e_1\ \texttt{op}\ e_1\Rightarrow_\stv\omega
      &\typrule \Gamma\Vdash (\texttt{op}\ e_1)\ e_2\Rightarrow_\stv\omega \\
    \Gamma\Vdash (e_i)\Rightarrow_\stv\omega
      &\typrule \Gamma\Vdash e_1\Rightarrow_{\stv_1}(\ldots(e_n\Rightarrow_{\stv_n}[(\stv_i)/\stv]\omega)\ldots) \\
    \Gamma\Vdash e.l\Rightarrow_\stv\omega
      &\typrule \Gamma,\etv\Vdash [\etv/\stv]\omega\Vdash e\Rightarrow_{\stv'} \stv'\leq \{l:\etv\} \\
    % check this, especially ordering of \etv_1 and \etv_2 in context!
    \Gamma\Vdash \textrm{let }x=e_1\textrm{ in }e_2\Rightarrow_\stv\omega
      &\typrule \Gamma,\etv_2,\etv_1\Vdash [\etv_2/\stv]\omega, x:\etv_1 \Vdash e_2\Leftarrow\etv_2\Vdash e_1\Leftarrow\etv_1 \\
    \Gamma\Vdash \textrm{case }e\ \{\rho_i, e_i\}\Rightarrow_\stv\omega
      &\typrule \Gamma,\etv\Vdash e\Rightarrow_{\stv'}(\{\rho_i\},\stv')\Rightarrow_{\stv''}\mathrm{cover}(\{\rho_i\},\stv''),\omega' \notag\\
      &\qquad\qquad\text{where }\omega'=(\rho_1,\stv'')\oplus e_1\Rightarrow_{\stv_1}\ldots(\rho_n,\stv'')\oplus e_n\Rightarrow_{\stv_n}\omega'' \notag\\
      &\qquad\qquad\text{and }\omega''=\stv_1\leq\etv,\ldots,\stv_{n-1}\leq\etv, [\etv/\stv]\omega \\
    \Gamma\Vdash f\ e_1 \ldots e_n\Rightarrow_\stv\omega
      &\typrule \Gamma\Vdash[\sigma/\stv]\omega\,@\,\{\Vdash e_i\Leftarrow \sigma_i\} \notag\\
      &\qquad\qquad\text{where }f:(\sigma_i)\rightarrow\sigma\in\Gamma\text{ and }n=\mathrm{len}(\sigma_i)
  \end{align}
  \caption{Expression typing rules (Parsley-specific)}
  \label{f:typecheck:parsley}
\end{figure}

\section*{TODOs}

The following are still being worked on in the type-system
specification:
\begin{itemize}
\item pattern matching details
\item type definitions
\item recursive types
\item recursive functions
\item grammar rules
\item modules, path resolution
\end{itemize}

The type rules are formulated for algorithmic type-checking, although
what we really need for an implementation is an algorithm for type
elaboration of the abstract syntax.  We could formulate this as an
extension of the type-checking algorithm.

The dynamic semantics will then need addressing.

\section*{Acknowledgments}
This work was supported by DARPA under agreement number HR001119C0075.
The views and conclusions contained herein are those of the authors
and should not be interpreted as necessarily representing the official
policies or endorsements, either expressed or implied, of DARPA or the
U.S. Government.

\bibliographystyle{plain}
\bibliography{parsley}
\end{document}
